#!/usr/bin/env python3
"""
Marketing Partner Analysis - ë§ˆì¼€íŒ… íŒŒíŠ¸ë„ˆ ë¶„ì„
Lake Formation FGAC ë°ëª¨ìš© - ê°•ë‚¨êµ¬ 20-30ëŒ€ë§Œ ì ‘ê·¼ (~1,650ê±´)
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
import sys

def create_spark_session():
    """S3 Tables(Iceberg) ì§€ì› Spark ì„¸ì…˜ ìƒì„±"""
    import os
    table_bucket = os.getenv('TABLE_BUCKET_NAME', 'seoul-bike-demo-2025')
    
    return SparkSession.builder \
        .appName("MarketingPartner-TargetAccess-Analysis") \
        .config("spark.sql.catalog.s3tables_catalog", "org.apache.iceberg.spark.SparkCatalog") \
        .config("spark.sql.catalog.s3tables_catalog.catalog-impl", "org.apache.iceberg.aws.s3.S3TablesCatalog") \
        .config("spark.sql.catalog.s3tables_catalog.warehouse", f"s3://{table_bucket}/") \
        .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
        .getOrCreate()

def main():
    print("=== Marketing Partner Analysis ì‹œì‘ ===")
    print("ì—­í• : ë§ˆì¼€íŒ… íŒŒíŠ¸ë„ˆ - ê°•ë‚¨êµ¬ 20-30ëŒ€ íƒ€ê²Ÿ ê³ ê°ë§Œ ì ‘ê·¼")
    
    spark = create_spark_session()
    
    try:
        # S3 Tablesì—ì„œ ë°ì´í„° ì½ê¸°
        print("\n1. S3 Tablesì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        spark_conf = spark.sparkContext.getConf()
        namespace = spark_conf.get('spark.app.s3tables.namespace', 'bike_db')
        table_name = spark_conf.get('spark.app.s3tables.table', 'bike_rental_data')
        
        print(f"   ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
        print(f"   í…Œì´ë¸”ëª…: {table_name}")
        
        df = spark.read.table(f"s3tables_catalog.{namespace}.{table_name}")
        
        total_records = df.count()
        print(f"âœ… Lake Formation í•„í„°ë§ í›„ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê±´")
        print("ğŸ”’ ì ‘ê·¼ ì œí•œ: ê°•ë‚¨êµ¬ + 20-30ëŒ€ë§Œ (birth_year ì§ì ‘ ì ‘ê·¼ ë¶ˆê°€)")
        
        # ë°ì´í„° ìŠ¤í‚¤ë§ˆ í™•ì¸ (ì ‘ê·¼ ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ)
        print("\n2. ì ‘ê·¼ ê°€ëŠ¥í•œ ë°ì´í„° ìŠ¤í‚¤ë§ˆ:")
        df.printSchema()
        
        # ì§€ì—­ í™•ì¸ (ê°•ë‚¨êµ¬ë§Œ ìˆì–´ì•¼ í•¨)
        print(f"\n3. ì ‘ê·¼ ê°€ëŠ¥í•œ ì§€ì—­ í™•ì¸:")
        district_check = df.groupBy("district").count().orderBy(desc("count"))
        district_check.show()
        
        # íƒ€ê²Ÿ ê³ ê° ì„±ë³„ ë¶„í¬
        print(f"\n4. íƒ€ê²Ÿ ê³ ê° ì„±ë³„ ë¶„í¬:")
        gender_distribution = df.groupBy("gender") \
                                .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                     avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„"),
                                     avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬")) \
                                .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        gender_distribution.show()
        
        # íƒ€ê²Ÿ ê³ ê° ì´ìš© íŒ¨í„´ - ì‹œê°„ëŒ€ë³„
        print(f"\n5. íƒ€ê²Ÿ ê³ ê° ì‹œê°„ëŒ€ë³„ ì´ìš© íŒ¨í„´:")
        hourly_pattern = df.withColumn("hour", hour("rental_date")) \
                           .groupBy("hour") \
                           .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„")) \
                           .orderBy("hour")
        
        hourly_pattern.show(24)
        
        # íƒ€ê²Ÿ ê³ ê° ìš”ì¼ë³„ ì´ìš© íŒ¨í„´
        print(f"\n6. íƒ€ê²Ÿ ê³ ê° ìš”ì¼ë³„ ì´ìš© íŒ¨í„´:")
        weekday_pattern = df.withColumn("weekday", date_format("rental_date", "EEEE")) \
                            .groupBy("weekday") \
                            .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                 avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„"),
                                 avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬")) \
                            .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        weekday_pattern.show()
        
        # ì¸ê¸° ì •ê±°ì¥ ë¶„ì„ (ë§ˆì¼€íŒ… í¬ì¸íŠ¸)
        print(f"\n7. íƒ€ê²Ÿ ê³ ê° ì¸ê¸° ì •ê±°ì¥ (ìƒìœ„ 10ê°œ):")
        popular_stations = df.groupBy("station_name", "station_id") \
                             .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                  countDistinct("rental_id").alias("ê³ ìœ _ì´ìš©ììˆ˜"),
                                  avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„"),
                                  avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬")) \
                             .orderBy(desc("ì´ìš©íšŸìˆ˜")) \
                             .limit(10)
        
        popular_stations.show(truncate=False)
        
        # ì´ìš© ì‹œê°„ ì„ í˜¸ë„ ë¶„ì„
        print(f"\n8. íƒ€ê²Ÿ ê³ ê° ì´ìš© ì‹œê°„ ì„ í˜¸ë„:")
        usage_preference = df.withColumn("usage_category",
                                       when(col("usage_min") <= 10, "ì§§ì€ì´ìš©(â‰¤10ë¶„)")
                                       .when(col("usage_min") <= 20, "ë³´í†µì´ìš©(11-20ë¶„)")
                                       .when(col("usage_min") <= 30, "ê¸´ì´ìš©(21-30ë¶„)")
                                       .otherwise("ë§¤ìš°ê¸´ì´ìš©(>30ë¶„)")) \
                            .groupBy("usage_category") \
                            .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                 avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬")) \
                            .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        usage_preference.show()
        
        # ì´ë™ ê±°ë¦¬ ì„ í˜¸ë„ ë¶„ì„
        print(f"\n9. íƒ€ê²Ÿ ê³ ê° ì´ë™ ê±°ë¦¬ ì„ í˜¸ë„:")
        distance_preference = df.withColumn("distance_category",
                                          when(col("distance_meter") <= 1000, "ê·¼ê±°ë¦¬(â‰¤1km)")
                                          .when(col("distance_meter") <= 2000, "ì¤‘ê±°ë¦¬(1-2km)")
                                          .when(col("distance_meter") <= 3000, "ì¥ê±°ë¦¬(2-3km)")
                                          .otherwise("ì´ˆì¥ê±°ë¦¬(>3km)")) \
                               .groupBy("distance_category") \
                               .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                    avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„")) \
                               .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        distance_preference.show()
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë¶„ì„
        print(f"\n10. íƒ€ê²Ÿ ê³ ê° ì‚¬ìš©ì ìœ í˜•:")
        user_type_analysis = df.groupBy("user_type") \
                               .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                                    avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„"),
                                    avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬")) \
                               .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        user_type_analysis.show()
        
        # ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ - í”¼í¬ ì‹œê°„ëŒ€
        print(f"\n11. ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ - í”¼í¬ ì‹œê°„ëŒ€:")
        peak_hours = df.withColumn("hour", hour("rental_date")) \
                       .withColumn("time_category",
                                 when(col("hour").between(7, 9), "ì¶œê·¼ì‹œê°„")
                                 .when(col("hour").between(12, 14), "ì ì‹¬ì‹œê°„")
                                 .when(col("hour").between(18, 20), "í‡´ê·¼ì‹œê°„")
                                 .when(col("hour").between(21, 23), "ì €ë…ì‹œê°„")
                                 .otherwise("ê¸°íƒ€ì‹œê°„")) \
                       .groupBy("time_category") \
                       .agg(count("*").alias("ì´ìš©íšŸìˆ˜"),
                            avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„")) \
                       .orderBy(desc("ì´ìš©íšŸìˆ˜"))
        
        peak_hours.show()
        
        # íƒ€ê²Ÿ ê³ ê° í–‰ë™ ìš”ì•½
        print(f"\n12. íƒ€ê²Ÿ ê³ ê° í–‰ë™ ìš”ì•½:")
        behavior_summary = df.agg(
            count("*").alias("ì´_ì´ìš©íšŸìˆ˜"),
            countDistinct("station_id").alias("ì´ìš©_ì •ê±°ì¥ìˆ˜"),
            avg("usage_min").alias("í‰ê· _ì´ìš©ì‹œê°„"),
            avg("distance_meter").alias("í‰ê· _ì´ë™ê±°ë¦¬"),
            expr("percentile_approx(usage_min, 0.5)").alias("ì¤‘ì•™ê°’_ì´ìš©ì‹œê°„"),
            expr("percentile_approx(distance_meter, 0.5)").alias("ì¤‘ì•™ê°’_ì´ë™ê±°ë¦¬")
        )
        
        behavior_summary.show()
        
        print(f"\n=== Marketing Partner Analysis ì™„ë£Œ ===")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {total_records:,}ê±´ (ê°•ë‚¨êµ¬ 20-30ëŒ€ë§Œ)")
        print(f"ğŸ”’ ê¶Œí•œ: ê°•ë‚¨êµ¬ + 20-30ëŒ€ íƒ€ê²Ÿ ê³ ê°ë§Œ (birth_year ì§ì ‘ ì ‘ê·¼ ë¶ˆê°€)")
        print(f"ğŸ“Š ì—­í• : íƒ€ê²Ÿ ë§ˆì¼€íŒ… ë¶„ì„ ë° ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    finally:
        spark.stop()

if __name__ == "__main__":
    main()
